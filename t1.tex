\section{Ordinary Differential Equations. Basic concepts}

\subsection{Introduction and some notation}

Given $y' = f(x,y)$, where $\begin{cases} y(x) \in \real^n\\ f:\real\times\real^n \to \real^n\end{cases}$

\begin{definition}
  We denote by $y(x)$ the exact solution of the ODE system above.
\end{definition}

\begin{definition}
  $y_k$ is the approximation of $y(x_k)$ (after $k$ steps).
\end{definition}

\begin{objective}
  We want to approximate $y(x)$ within a given interval $[x_0, x_n]$. \\
  \footnotesize{
  \begin{multicols}{3}
    We know $\begin{cases}x_0\\x_1\\x_2\\\vdots\\x_n \end{cases}$\\
    \-\hspace{-2cm}We'd like to know $\begin{cases}y(x_0)\\y(x_1)\\y(x_2)\\\vdots \\y(x_n) \end{cases}$\\
    \-\hspace{-2cm}We find $\begin{cases} y_0\\y_1\\y_2\\\vdots \\y_n \end{cases}$ (given by a method)
  \end{multicols}
  }
\end{objective}
\normalsize
\begin{definition}
  $\norm{y(x_n) - y_n}$ is the \textbf{global error}.
\end{definition}

\begin{definition}
  We define the \textbf{local truncation error} as the error caused by one iteration, i.e. $$LTE = \norm{y(x_k) - y_k} \qquad \text{\big(assuming the \textit{localizing assumption}: $y_{k-1} = y(x_{k-1})$\big)}$$
\end{definition}

\begin{definition}
  A method is of \textbf{order} $p$ if the LTE is of the form $$\text{LTE} = Ch^{p+1} + \mathcal{O}(h^{p+2})$$
\end{definition}

\subsection{Euler's method}
\subsubsection{Formulation}
Consider the differential equation system
\begin{equation}\label{sys1.2}
  y'(x) = f(y(x)), \qquad y(x_0) = y_0 \qquad (\text{with } f:\real^n \to \real^n)
\end{equation}

We'll also assume, for later results, that $f$ satisfies a Lipschitz condition $$\norm{f(y) - f(z)} \leq L\norm{y-z}$$

Now, we want to find an approximation of (\ref{sys1.2}) on an interval $[x_0, x_N]$, so we'll create a set of $N+1$ evenly spaced points between $x_0$ and $x_N$, where $N$ is the number of steps and $h = \dfrac{x_N-x_0}{N}$ the stepsize.\\

To do that, we can use Euler's method
\[
  y_{n+1} = y_n + hf(y_n)
\]

\newpage

\subsubsection{Local truncation error}

We want to find $LTE = \norm{y(x_{n+1}) - y_{n+1}}$. Let's expand it

\begin{align*}
    y(x_{n+1}) - y_{n+1} &= y(x_n + h) - y_{n+1} = y(x_n) + hy'(x_n) + \mathcal{O}(h^2) - y_n - hf(y_n) \underset{\text{Loc.ass.}}{=} \\
    &= y(x_n)+ hy'(x_n) + \mathcal{O}(h^2) - y(x_n) - hf(y_{x_n}) \\
    &= hy'(x_n) + \mathcal{O}(h^2) - hy'(x_n) = \mathcal{O}(h^2)
\end{align*}
  
So LTE = $\mathcal{O}(h^2)$, and the method has order $p=1$.

\subsubsection{Convergence}

For the method to be convergent, it has to verify $$\norm{y(x_N) - y_N} \underset{h\to0}{\longrightarrow} 0$$

Similar as what we did with the LTE, we'll find a bound for the error in one step, but this time without using the localizing assumption:

\begin{align*}
    \norm{y(x_{n+1}) - y_{n+1}} &= \norm{y(x_n + h) - y_n - hf(y_n)} \underset{\text{Taylor}}{=} ||y(x_n) + h\underbrace{y'(x_n)}_{f(y(x_n))} + \Tilde{c}h^2 - y_n - hf(y_n)|| \\
    &\leq \norm{y(x_n) - y_n} + h\underbrace{\norm{f(y(x_n)) - f(y_n)}}_{\substack{\text{\rotatebox{270}{$\leq$}} \\ L\norm{y(x_n) - y_n}}} + ch^2 \leq (1+hL)\norm{y(x_n) - y_n} + ch^2 \quad \forall n
\end{align*}

Thus
\begin{align*}
    &\norm{y(x_1) - y_1} \leq (1+hL)\norm{y(x_0) - y_0} + c_1h^2 \\
    &\norm{y(x_2) - y_2} \leq (1+hL)\norm{y(x_1) - y_1} + c_2h^2 \leq (1+hL)^2\norm{y(x_0) - y_0} + (1+hL)c_1h^2 + c_2h^2 \\
    &\norm{y(x_3) - y_3} \leq (1+hL)^3\norm{y(x_0) - y_0} + (1+hL)^2c_1h^2 + (1+hL)c_2h^2 + c_3h^2\\
    &\hspace{1.2cm}\vdots
\end{align*}
%\-\\
Let $C = \underset{i}{\text{max}}\,c_i$ \\

Then
\begin{align*}
    \norm{y(x_N) - y_N} \leq (1+hL)^N \norm{y(x_0) - y_0} + \underbrace{\Big(1 + (1+hL) + (1+hL)^2 + \ldots + (1+hL)^{N-1}\Big)}_{\substack{\text{\hspace{-0.94cm}geom$\to\,$\rotatebox{90}{$=$}}\\\frac{(1+hL)^N-1}{hL}}}Ch^2
\end{align*}

\[
  \implies \norm{y(x_n) - y_N} \leq (1+hL)^N\underbrace{\norm{y(x_0) - y_0}}_{\substack{\text{\hspace{-0.6cm}(\ref{sys1.2})\,\rotatebox{90}{=}}\\ 0}} + \frac{(1+hL)^N-1}{\cancel{h}L}\cdot Ch^{\cancel{2}} \leq Ah \to 0
\]

\begin{remark}
  In the last inequality we used $(1+hL)^N = e^{N\log(1+hL)} \underset{\substack{\log(1+x)\\\leq x + cx^2}}{=} e^{NhL + \alpha Nh^2} =$ $=e^{L(x_N-x_0)}\cdot e^{ch}\qquad$ ($Nh = x_n-x_0$)
\end{remark}

\newpage

\subsection{Improved Euler's method} \label{imprEu}
\subsubsection{Formulation}
\begin{figure}[h]
    \centering
    \definecolor{zzqqtt}{rgb}{0.6,0.,0.2}
    \definecolor{qqttzz}{rgb}{0.,0.2,0.6}
    \definecolor{qqwwzz}{rgb}{0.,0.4,0.6}
    \definecolor{xdxdff}{rgb}{0.49019607843137253,0.49019607843137253,1.}
    
    \begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=0.9285714285714286cm,y=0.9090909090909091cm]
    \begin{axis}[
    x=0.9285714285714286cm,y=0.9090909090909091cm,
    axis lines=middle,
    xmin=-1.0,
    xmax=13.0,
    ymin=-1.0,
    ymax=10.0,
    xtick={-0.0},
    ytick={-0.0},]
    \clip(-1.,-1.) rectangle (13.,10.);
    \draw[line width=1.pt,smooth,samples=100,domain=1.2000000009119923E-2:13.0] plot(\x,{ln((\x)^(5.0))-5.0});
    \draw [->,line width=1.pt,color=qqwwzz] (4.789374476513226,2.831999067204186) -- (9.680475596667712,8.660000685442492);
    \draw [->,line width=1.pt,color=qqwwzz] (4.789374476513226,2.831999067204186) -- (7.261114317049705,5.777205767419718);
    \draw [->,line width=1.pt,color=xdxdff] (7.261114317049705,5.777205767419718) -- (12.459510324028214,8.81562663017468);
    \draw [->,line width=1.pt,color=xdxdff] (4.789374476513226,2.831999067204186) -- (10.,6.);
    \draw [->,line width=1.pt,color=qqttzz] (9.680475596667712,8.660000685442492) -- (10.,6.);
    \draw [->,line width=1.pt,color=qqttzz] (4.789374476513226,2.831999067204186) -- (9.827482089829717,7.436190020287211);
    \draw [->,line width=1.pt,color=zzqqtt] (4.789374476513226,2.831999067204186) -- (7.731770530417767,5.520975629746587);
    \draw (6.279627438393455,6.60187417823135) node[anchor=north west] {$y_{n+1}^*$};
    \draw (4.257396566874901,3.6040056055416194) node[anchor=north west] {$y_n$};
    \draw [color=zzqqtt](7.7,5.5) node[anchor=north west] {$y_{n+1}$};
    \draw (10.714344261899054,9.475570679862926) node[anchor=north west] {$f(y_{n+1}^*)$};
    \draw (11.35294348448386,7.258212268110167) node[anchor=north west] {$y$};
    \draw (8.0,8.8) node[anchor=north west] {$f(y_n)$};
    \begin{scriptsize}
    \draw [fill=xdxdff] (4.789374476513226,2.831999067204186) circle (2.5pt);
    \draw [fill=xdxdff] (7.261114317049705,5.777205767419718) circle (2.5pt);
    \draw [fill=zzqqtt] (7.731770530417767,5.520975629746587) circle (2.5pt);
    \end{scriptsize}
    \end{axis}
    \end{tikzpicture}
    \caption{One step of the enhanced Euler's method}
    \label{fig:EnhancedEuler}
\end{figure}\-\\

Given $y'(x) = f(y(x)), \quad y: \real \to \real, \quad f:\real \to \real$, we'll go through the steps to deduce the improved Euler's method (also called Heun's method) with the help of the scheme in \text{Figure \ref{fig:EnhancedEuler}}. \\

The auxiliary point $y_{n+1}^*$ can be found doing one step of the standard Euler's method, so 

\[
  y_{n+1}^* = y_n + h\cdot f(y_n)
\]
\vspace{0.01cm}

To get the point $y_{n+1}$ we compute the average vector of $f(y_{n+1}^*)$ and $f(y_n)$, and with this new vector, we can apply again a step of Euler's method, ending up with our method

\[
  \boxed{y_{n+1} = y_n + \frac{h}{2}\cdot \left(f(y_{n+1}^*) + f(y_n)\right)}
\]
\newpage

\subsubsection{Local truncation error}

The Local Truncation Error is given by:

\[
  LTE = \norm{\textit{method} - \textit{exact solution}}
\]

Then

\[
  LTE = \norm{y_{n+1} - y(x_{n+1})} = \Big\rVert y_n + \frac{h}{2}f(y_n) + \frac{h}{2}f(y_{n+1}^*) - \underbrace{y(x_{n+1})}_{y(x_n + h)}\Big\rVert = (*)
\]

Applying Taylor on $f(y_{n+1}^*) = f\left(y_n + hf(y_n)\right)$, we have

\[
  f\left(y_n + hf(y_n)\right) = f(y_n) + hf(y_n)f'(y_n) + \mathcal{O}(h^2)
\]
\\
and on $y(x_n +h)$ we have

\[
  y(x_n + h) = y(x_n) + h\cdot y'(x_n) + \frac{h^2}{2}\cdot y''(x_n) + \mathcal{O}(h^3)
\]

(In this case, we expand to second order for later simplifications)

\footnotesize

\[
    (*) = \norm{y_n + \frac{h}{2}f(y_n) + \frac{h}{2}\left(f(y_n) + hf(y_n)f'(y_n) + \mathcal{O}(h^2) \right) - \left(y(x_n) + h\cdot y'(x_n) + \frac{h^2}{2}\cdot y''(x_n) + \mathcal{O}(h^3) \right)} \quad (1)
\]

\normalsize
\-\\
Now, given $y'(x) = f(y(x))$, we have

\vspace{-0.5cm}

\begin{align*}
    y''(x) &= f'(y(x))\cdot y'(x) \\
           &= f'(y(x)) \cdot f(y(x))
\end{align*}

and we can rewrite the following expression as:

\[
  \frac{h^2}{2}f(y(x))f'(y(x)) = \frac{h^2}{2}y''(x)
\]

With that and the localising assumption ($y_n = y(x_n)$), we can simplify most of the terms in (1) and we end up with

\small

\[
  \norm{\cancel{y_n} + \bcancel{\frac{h}{2}f(y_n) + \frac{h}{2}f(y_n)} + \xcancel{\frac{h^2}{2}f(y_n)f'(y_n)} + \mathcal{O}(h^3)  - \left(\cancel{y(x_n)} + \bcancel{h\cdot y'(x_n)} + \xcancel{\frac{h^2}{2}\cdot y''(x_n)} + \mathcal{O}(h^3) \right)} = \mathcal{O}(h^3)
\]

\normalsize
\-\\\\
So LTE $= \mathcal{O}(h^3)$\\

\begin{remark}
  Of course, this method also works for $y: \real \to \mathbb{R}^n, \, f:\real^n \to \real^n$
\end{remark}

\subsection{Final remarks}
\begin{itemize}
    \item There's an enhanced Euler's method of order $2$ similar to the previous one: $$\boxed{y_{n+1} = y_n + hf\left(\frac{y_{n+1}^* + y_n}{2}\right)}$$
    \item If we have a method of order $\geq 2$, and we want the value of $y(x^*)$, with $x^*$ off the mesh ($x^* \not= k\cdot h$), we have some options:\\
    
    $\quad$-Step back and take a step with the right $h$.\\
    
    $\quad$-Interpolate with the right order.\\
    
    $\quad$-Use a continuous Runge-Kutta method.
\end{itemize}
